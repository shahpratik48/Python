{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7d0bf048-c94c-4104-93d4-8a238b43e658",
      "metadata": {
        "id": "7d0bf048-c94c-4104-93d4-8a238b43e658"
      },
      "source": [
        "# House Price Prediction Using Machine Learning\n",
        "\n",
        "## Introduction\n",
        "\n",
        "This project demonstrates the creation of an end-to-end machine learning pipeline for predicting house prices. By leveraging the power of regression models, we aim to predict the target variable, `SalePrice`, based on various features such as location, size, and other property characteristics.\n",
        "\n",
        "### Objectives\n",
        "\n",
        "- Build a regression model to predict house prices using the `AmesHousing` dataset.\n",
        "- Follow a structured approach to preprocess the data, train the model, and evaluate its performance.\n",
        "- Save the trained model and preprocessing steps for future use.\n",
        "- Deploy the model as an interactive web application using Streamlit.\n",
        "\n",
        "### Tools and Libraries Used\n",
        "\n",
        "- **Python**: For coding the machine learning pipeline.\n",
        "- **Scikit-learn**: For preprocessing, modeling, and evaluation.\n",
        "- **Pandas**: For data manipulation and analysis.\n",
        "- **Streamlit**: For creating an interactive web app for deployment.\n",
        "- **Joblib**: For saving and loading machine learning models and pipelines.\n",
        "\n",
        "### Workflow Overview\n",
        "\n",
        "1. **Loading Data**: Import and explore the dataset to understand its structure.\n",
        "2. **Data Preprocessing**: Clean the data, handle missing values, and perform feature scaling and encoding.\n",
        "3. **Data Splitting**: Divide the dataset into training and testing sets.\n",
        "4. **Model Selection**: Choose an appropriate regression algorithm.\n",
        "5. **Model Training and Evaluation**: Train the model on the training set and evaluate its performance.\n",
        "6. **Saving Artifacts**: Save the trained model and preprocessing steps for deployment.\n",
        "7. **Streamlit Deployment**: Create an interactive web app for real-time predictions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d9c9d04-0df6-47a8-86a8-d4133140c32e",
      "metadata": {
        "id": "7d9c9d04-0df6-47a8-86a8-d4133140c32e"
      },
      "source": [
        "##**Step 1 - Load the Data**\n",
        "\n",
        "The first step in any machine learning pipeline is to load and examine the dataset. Here, we:\n",
        "\n",
        "1. Load the dataset using pandas.\n",
        "2. Separate the features (independent variables) and the target variable (`SalePrice`).\n",
        "\n",
        "The target variable is what the regression model will learn to predict. The features are the input variables the model uses to make predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc4bb336-075c-4e9d-9c20-9b7cc367829f",
      "metadata": {
        "id": "dc4bb336-075c-4e9d-9c20-9b7cc367829f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('AmesHousing.csv')\n",
        "\n",
        "# Seperate the feature columns and the target column 'SalePrice'\n",
        "X = data.drop(columns=['SalePrice'])\n",
        "y = data['SalePrice']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c03e1f2-e55e-4464-9fb6-2e63db070743",
      "metadata": {
        "id": "7c03e1f2-e55e-4464-9fb6-2e63db070743"
      },
      "source": [
        "##**Step 2 - Preprocess the Data**\n",
        "\n",
        "Data preprocessing is critical for ensuring the dataset is ready for training the machine learning model. This step includes:\n",
        "\n",
        "1. **Handling Missing Values:** Replace missing values with appropriate statistics (e.g., mean, median) or other strategies.\n",
        "2. **Standardizing Numerical Features:** Scale numerical data to have a mean of zero and a standard deviation of one for consistent model performance.\n",
        "3. **Encoding Categorical Variables:** Convert categorical features into numerical representations using methods such as one-hot encoding.\n",
        "4. **Building Pipelines:** Use pipelines to automate the preprocessing steps, ensuring all data transformations are applied consistently.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67167ab4-cb6d-436f-89de-e432099c2dbe",
      "metadata": {
        "id": "67167ab4-cb6d-436f-89de-e432099c2dbe"
      },
      "outputs": [],
      "source": [
        "# Identify numeric and categorical columns\n",
        "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = X.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Create pipelines for the numeric and categorical data\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "# Combine the pipelines using ColumnTransformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)])\n",
        "\n",
        "# Use the preprocessor on the data\n",
        "X_preprocessed = preprocessor.fit_transform(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e08c985e-4fc1-486d-aae8-ffa32b6cafcc",
      "metadata": {
        "id": "e08c985e-4fc1-486d-aae8-ffa32b6cafcc"
      },
      "source": [
        "##**Step 3 - Splitting Data**\n",
        "\n",
        "Before training the model, the dataset is split into training and testing sets. This helps evaluate the model's performance on unseen data. Key aspects of this step include:\n",
        "\n",
        "1. **Training Data:** Used to train the machine learning model.\n",
        "2. **Testing Data:** Used to evaluate the model's performance and generalization ability.\n",
        "\n",
        "The `train_test_split` function from scikit-learn splits the dataset into training and testing sets in a controlled manner, typically with an 80-20 or 70-30 split.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e36c43a-b2a9-4637-b06c-3835a4a2ca5d",
      "metadata": {
        "id": "2e36c43a-b2a9-4637-b06c-3835a4a2ca5d"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50a63c54-1f28-4512-a915-5b29652e62fa",
      "metadata": {
        "id": "50a63c54-1f28-4512-a915-5b29652e62fa"
      },
      "source": [
        "##**Step 4 - Choosing a Model**\n",
        "\n",
        "Selecting the right machine learning algorithm is crucial for building an effective model. For regression problems like house price prediction, commonly used models include:\n",
        "\n",
        "1. **Linear Regression:** Assumes a linear relationship between features and the target variable.\n",
        "2. **Random Forest Regressor:** An ensemble method that builds multiple decision trees and averages their predictions.\n",
        "3. **Gradient Boosting Regressor:** An advanced ensemble method that builds trees sequentially to minimize error.\n",
        "\n",
        "The choice of model depends on the problem's complexity and dataset characteristics.\n",
        "\n",
        "Here, a Random Forest Regressor is chosen due to its robustness and ability to handle both numerical and categorical data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3ab7959-fa67-4191-8d3d-ff4ea7543094",
      "metadata": {
        "id": "e3ab7959-fa67-4191-8d3d-ff4ea7543094"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Initialize the model\n",
        "model = LinearRegression()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c233a36f-b359-4bef-96b4-bba80b8aeb3a",
      "metadata": {
        "id": "c233a36f-b359-4bef-96b4-bba80b8aeb3a"
      },
      "source": [
        "## **Step 5 - Training and Evaluating the Model**\n",
        "\n",
        "Once the model is selected, it is trained using the training dataset and evaluated on the testing dataset. This step includes:\n",
        "\n",
        "1. **Training:** The model learns the patterns in the training data.\n",
        "2. **Evaluation:** The model's performance is assessed using metrics such as Mean Squared Error (MSE), Root Mean Squared Error (RMSE), and RÂ² Score.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1602469-15c4-4dcd-9b6b-b3d81227f35b",
      "metadata": {
        "id": "f1602469-15c4-4dcd-9b6b-b3d81227f35b",
        "outputId": "b801affb-3472-4108-c73f-69b7e9a9d212"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAE: 16033.130197388631\n",
            "RMSE: 29634.797688916115\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import joblib\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "\n",
        "print(f'MAE: {mae}')\n",
        "print(f'RMSE: {rmse}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e460605-50a7-461b-a4fe-5ca21618bdb0",
      "metadata": {
        "id": "1e460605-50a7-461b-a4fe-5ca21618bdb0"
      },
      "source": [
        "## **Step 6 - Saving the Model**\n",
        "\n",
        "After training, the model is saved to a file. This allows reusability without needing to retrain. Popular libraries for saving models include:\n",
        "\n",
        "1. **joblib:** Efficiently saves models and transformers.\n",
        "2. **pickle:** Serializes Python objects for storage.\n",
        "\n",
        "The trained model is saved as a .pkl file for later use.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52a5da9e-3fa2-47ca-82e5-9a2a1c77d094",
      "metadata": {
        "id": "52a5da9e-3fa2-47ca-82e5-9a2a1c77d094",
        "outputId": "455bc175-193a-4c55-e2bd-ac5d15afb5e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['house_price_model.pkl']"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save the model\n",
        "model_file = 'house_price_model.pkl'\n",
        "joblib.dump(model, model_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a8b3b5c-ab6c-48ba-be11-66e1ddd50368",
      "metadata": {
        "id": "0a8b3b5c-ab6c-48ba-be11-66e1ddd50368"
      },
      "source": [
        "## **Step 7 - Saving the Preprocessor**\n",
        "\n",
        "The preprocessing steps applied to the training data must also be saved. This ensures that the same transformations are applied to any new data during inference.\n",
        "\n",
        "The preprocessor pipeline is saved for use in the Streamlit app."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab94695d-6d28-4071-996d-50e9b901bd1a",
      "metadata": {
        "id": "ab94695d-6d28-4071-996d-50e9b901bd1a",
        "outputId": "f225e0ab-5923-48e8-d75a-7aea1e5ba831"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['preprocessor.pkl']"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "# Save the preprocessor\n",
        "preprocessor_file = 'preprocessor.pkl'  # Save path for the preprocessor\n",
        "joblib.dump(preprocessor, preprocessor_file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bcb3fc2-00ee-467a-9f1f-9126180896de",
      "metadata": {
        "id": "8bcb3fc2-00ee-467a-9f1f-9126180896de"
      },
      "source": [
        "##**Step 8 - Building a Streamlit App**\n",
        "\n",
        "Streamlit allows you to create interactive web apps for machine learning models. The app will:\n",
        "\n",
        "1. Load the saved model and preprocessor.\n",
        "2. Take user input for feature values.\n",
        "3. Make predictions and display the results.\n",
        "\n",
        "\n",
        "##### save the below file as app.py in the same folder and on the command line in VS Code type: streamlit run app.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b62329c5-2583-457c-914a-8f7cfc096d59",
      "metadata": {
        "id": "b62329c5-2583-457c-914a-8f7cfc096d59"
      },
      "outputs": [],
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import numpy as np\n",
        "\n",
        "# Load the trained model\n",
        "model = joblib.load('house_price_model.pkl')\n",
        "\n",
        "# Load the preprocessor\n",
        "preprocessor = joblib.load('preprocessor.pkl')\n",
        "\n",
        "# Define the input fields\n",
        "st.title('House Price Prediction')\n",
        "\n",
        "# Input fields\n",
        "# Here, more complex features (strings/categorical) should be made into st.selectbox etc.\n",
        "\n",
        "# Example numeric fields for simplicity:\n",
        "lot_area = st.number_input('Lot Area', value=5000)\n",
        "overall_qual = st.number_input('Overall Qual', min_value=1, max_value=10, value=5)\n",
        "year_built = st.number_input('Year Built', value=1990)\n",
        "total_bsmt_sf = st.number_input('Total Bsmt SF', value=1000)\n",
        "first_flr_sf = st.number_input('1st Flr SF', value=1000)\n",
        "full_bath = st.number_input('Full Bath', value=2)\n",
        "gr_liv_area = st.number_input('Gr Liv Area', value=1500)\n",
        "garage_cars = st.number_input('Garage Cars', value=1)\n",
        "# You need to add more fields for all the mentioned features in a similar way here...\n",
        "\n",
        "# Create a DataFrame for the input features\n",
        "# Make sure the names of input fields match the ones expected by the preprocessor\n",
        "input_data = pd.DataFrame({\n",
        "    'Central Air': ['Y'],  # Example of default input for categorical feature\n",
        "    'House Style': ['1Story'],  # Just examples for missing fields\n",
        "    'Bsmt Full Bath': [1],\n",
        "    'Kitchen Qual': ['TA'],\n",
        "    'Bsmt Qual': ['TA'],\n",
        "    'Exter Cond': ['TA'],\n",
        "    'Neighborhood': ['NAmes'],\n",
        "    'Garage Qual': ['TA'],\n",
        "    'Bedroom AbvGr': [3],\n",
        "    'MS Zoning': ['RL'],\n",
        "    'Foundation': ['PConc'],\n",
        "    'Misc Val': [0],\n",
        "    'Fireplaces': [0],\n",
        "    'Bsmt Unf SF': [400],\n",
        "    'Low Qual Fin SF': [0],\n",
        "    'Land Contour': ['Lvl'],\n",
        "    'Bldg Type': ['1Fam'],\n",
        "    'Garage Cond': ['TA'],\n",
        "    'Bsmt Cond': ['TA'],\n",
        "    'Alley': ['NA'],\n",
        "    'Condition 2': ['Norm'],\n",
        "    'Condition 1': ['Norm'],\n",
        "    'Wood Deck SF': [0],\n",
        "    'Overall Cond': [5],\n",
        "    'Lot Config': ['Inside'],\n",
        "    'Screen Porch': [0],\n",
        "    'Lot Shape': ['Reg'],\n",
        "    '3Ssn Porch': [0],\n",
        "    'Fence': ['NA'],\n",
        "    'Exterior 1st': ['VinylSd'],\n",
        "    'Land Slope': ['Gtl'],\n",
        "    'Heating QC': ['Ex'],\n",
        "    'Street': ['Pave'],\n",
        "    'Utilities': ['AllPub'],\n",
        "    'MS SubClass': [20],\n",
        "    'Exterior 2nd': ['VinylSd'],\n",
        "    'Roof Style': ['Gable'],\n",
        "    'Open Porch SF': [20],\n",
        "    'Bsmt Exposure': ['No'],\n",
        "    'Kitchen AbvGr': [1],\n",
        "    'Paved Drive': ['Y'],\n",
        "    'Year Remod/Add': [2000],\n",
        "    'Garage Area': [500],\n",
        "    'Pool QC': ['NA'],\n",
        "    'Electrical': ['SBrkr'],\n",
        "    'Roof Matl': ['CompShg'],\n",
        "    'Sale Condition': ['Normal'],\n",
        "    'Mo Sold': [6],\n",
        "    'Misc Feature': ['NA'],\n",
        "    'Bsmt Half Bath': [0],\n",
        "    'Sale Type': ['WD'],\n",
        "    'Half Bath': [1],\n",
        "    'Garage Type': ['Attchd'],\n",
        "    'Heating': ['GasA'],\n",
        "    'BsmtFin SF 1': [500],\n",
        "    'Yr Sold': [2010],\n",
        "    'Functional': ['Typ'],\n",
        "    'Pool Area': [0],\n",
        "    'Exter Qual': ['TA'],\n",
        "    'Garage Finish': ['Unf'],\n",
        "    'Mas Vnr Type': ['None'],\n",
        "    'Mas Vnr Area': [0],\n",
        "    'Garage Yr Blt': [1990],\n",
        "    'Enclosed Porch': [0],\n",
        "    'TotRms AbvGrd': [6],\n",
        "    'Order': [1],\n",
        "    'Fireplace Qu': ['NA'],\n",
        "    'BsmtFin Type 2': ['NA'],\n",
        "    'PID': [0],  # Note this should be handled appropriately as it may not be in preprocessing\n",
        "    'BsmtFin Type 1': ['GLQ'],\n",
        "    'Lot Frontage': [60],\n",
        "    'BsmtFin SF 2': [0],\n",
        "    '2nd Flr SF': [0],\n",
        "\n",
        "    # Features defined by the user\n",
        "    'Lot Area': [lot_area],\n",
        "    'Overall Qual': [overall_qual],\n",
        "    'Year Built': [year_built],\n",
        "    'Total Bsmt SF': [total_bsmt_sf],\n",
        "    '1st Flr SF': [first_flr_sf],\n",
        "    'Full Bath': [full_bath],\n",
        "    'Gr Liv Area': [gr_liv_area],\n",
        "    'Garage Cars': [garage_cars],\n",
        "})\n",
        "\n",
        "# Preprocess the input features\n",
        "input_features_preprocessed = preprocessor.transform(input_data)\n",
        "\n",
        "# Predict and display the output\n",
        "if st.button('Predict'):\n",
        "    prediction = model.predict(input_features_preprocessed)\n",
        "    st.write(f'Predicted House Price: ${prediction[0]:,.2f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56375638-3c86-4ec8-8822-95b666ef855c",
      "metadata": {
        "id": "56375638-3c86-4ec8-8822-95b666ef855c"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}