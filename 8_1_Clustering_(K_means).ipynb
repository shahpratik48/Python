{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "808543ec-e106-41db-9ea5-90b1c981af6e",
      "metadata": {
        "id": "808543ec-e106-41db-9ea5-90b1c981af6e"
      },
      "source": [
        "# Clustering with K-Means\n",
        "\n",
        "**Clustering** is an unsupervised learning technique used to group similar data points into clusters. One of the most popular clustering algorithms is **K-Means**. K-Means partitions the data into **K** clusters, where each data point belongs to the cluster with the nearest mean. It's widely used in data analysis, image compression, and customer segmentation.\n",
        "\n",
        "### Steps in K-Means Clustering:\n",
        "1. **Initialization**: Randomly select K data points as the initial centroids (center points of clusters).\n",
        "2. **Assignment Step**: Assign each data point to the nearest centroid.\n",
        "3. **Update Step**: Recalculate the centroids based on the mean of the points assigned to each cluster.\n",
        "4. **Repeat**: Repeat the assignment and update steps until the centroids no longer change or the algorithm converges.\n",
        "\n",
        "### How K-Means Works:\n",
        "- **K** represents the number of clusters that the algorithm will form.\n",
        "- The **centroids** are the central points of each cluster and are updated during the algorithm's execution.\n",
        "- **Euclidean distance** is typically used to measure the distance between data points aikit-learn matplotlib\n",
        "\n",
        "### Applications\n",
        "K-means clustering is versatile and can be applied in various domains, including:\n",
        "- **Market Segmentation**: Grouping customers based on purchasing behavior.\n",
        "- **Anomaly Detection**: Identifying outliers or unusual patterns in data.\n",
        "- **Customer Grouping**: Categorizing customers for targeted marketing."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b42418e-66ae-4ff1-b965-47198dbab1f4",
      "metadata": {
        "id": "5b42418e-66ae-4ff1-b965-47198dbab1f4"
      },
      "source": [
        "# Using K-Means for Classification (Clustering - Unsupervized ML):"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Elbow Method\n",
        "\n",
        "### What is the Elbow Method?\n",
        "The Elbow Method is used to determine the optimal number of clusters (`K`) for K-means clustering. It involves plotting the inertia (sum of squared distances from each point to its cluster centroid) against the number of clusters and identifying the \"elbow point.\"\n",
        "\n",
        "### Steps:\n",
        "1. Run K-means for a range of values of `K`.\n",
        "2. Calculate inertia for each value of `K`.\n",
        "3. Plot `K` vs. inertia.\n",
        "4. Identify the \"elbow,\" where the rate of decrease in inertia slows significantly. This point represents the optimal `K`.\n",
        "\n",
        "### Why Use the Elbow Method?\n",
        "- To avoid underfitting or overfitting by choosing a reasonable number of clusters."
      ],
      "metadata": {
        "id": "9HFdZg69wbxo"
      },
      "id": "9HFdZg69wbxo"
    },
    {
      "cell_type": "markdown",
      "id": "f56a5c1f-1a38-4c14-a1f8-7715d9300ea5",
      "metadata": {
        "id": "f56a5c1f-1a38-4c14-a1f8-7715d9300ea5"
      },
      "source": [
        "## **1. Elbow Method for Determining Optimal Clusters**\n",
        "\n",
        "In addition to visual inspection, the optimal K can be determined programmatically by monitoring the percentage change in inertia. If the change remains below a certain threshold (e.g., 5%) for three consecutive K values, the optimal K is identified.\n",
        "\n",
        "### Visualizing Clusters\n",
        "After determining the optimal K, the final K-means model is fitted to the data. Clusters can then be visualized by plotting data points, colored by their assigned cluster labels. This helps in interpreting the cluster structure and verifying the clustering results.\n",
        "\n",
        "### Steps in the Implementation\n",
        "1. **Load the Dataset**: Load the dataset containing features such as marks and study hours.\n",
        "2. **Normalize the Data**: Apply Min-Max scaling to ensure equal contribution from all features.\n",
        "3. **Determine Optimal Clusters**: Use the elbow method to plot inertia and identify the optimal K.\n",
        "4. **Fit the Final Model**: Train the K-means model using the optimal K.\n",
        "5. **Visualize Clusters**: Plot the data points with cluster assignments.\n",
        "6. **Output Optimal K**: Display the number of clusters chosen.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample Code:"
      ],
      "metadata": {
        "id": "l4DytNppzD8O"
      },
      "id": "l4DytNppzD8O"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c650723-3ab4-4347-9ebe-14e955ebc645",
      "metadata": {
        "id": "7c650723-3ab4-4347-9ebe-14e955ebc645"
      },
      "outputs": [],
      "source": [
        "# Import pandas for data processing\n",
        "import pandas as pd\n",
        "\n",
        "# Read the dataset\n",
        "dataset = pd.read_csv(\"studentclusters.csv\")\n",
        "X = dataset.copy()\n",
        "\n",
        "# Visualize the data using Scatter plot (optional, just to see the raw data)\n",
        "X.plot.scatter(x='marks', y='shours')\n",
        "\n",
        "# Fit and Transform the data for MinMax normalization\n",
        "from sklearn.preprocessing import minmax_scale\n",
        "X_scaled = minmax_scale(X)\n",
        "\n",
        "# Elbow method to determine optimum clusters\n",
        "inertia_values = []  # To store inertia values\n",
        "\n",
        "\n",
        "# import KMeans for clustering\n",
        "from sklearn.cluster import KMeans\n",
        "# Try different numbers of clusters (from 2 to 15)\n",
        "for i in range(2, 6):\n",
        "    kmeans = KMeans(n_clusters=i, random_state=42)  # Set random_state for reproducibility\n",
        "    kmeans.fit(X_scaled)\n",
        "    inertia_values.append(kmeans.inertia_)\n",
        "\n",
        "# Plotting the Elbow Curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(range(2, 6), inertia_values, marker='o')\n",
        "plt.title('Elbow Method for Optimal K')\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('Inertia (Sum of Squared Distances)')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What Does the Code Achieve?\n",
        "### 1. Loads and Prepares the Data\n",
        "- The dataset is read, and its features are normalized using MinMax scaling.\n",
        "- This ensures fair contribution of all attributes in the clustering process, as K-means is sensitive to the scale of features.\n",
        "\n",
        "\n",
        "\n",
        "### 2. Explores the Data\n",
        "- A scatter plot is generated to provide an initial view of the data's distribution.\n",
        "- This helps understand the relationship between the features (`marks` and `study hours`) visually.\n",
        "\n",
        "\n",
        "\n",
        "### 3. Applies K-means Clustering\n",
        "- The data is clustered for different numbers of clusters (`K`).\n",
        "- For each value of `K`, the clustering is performed, and the inertia (a measure of clustering quality) is calculated.\n",
        "\n",
        "\n",
        "\n",
        "### 4. Determines the Optimal Number of Clusters\n",
        "- The Elbow Method is used to find the optimal value of `K` by analyzing the inertia values.\n",
        "- The \"elbow point,\" where the rate of decrease in inertia slows significantly, represents the optimal number of clusters.\n",
        "\n",
        "\n",
        "### 5. Visualizes the Results\n",
        "- The Elbow Curve is plotted to visualize how inertia changes with the number of clusters.\n",
        "- This visual representation helps identify the optimal value of `K` effectively.\n"
      ],
      "metadata": {
        "id": "Iq_d7cOHv8Mn"
      },
      "id": "Iq_d7cOHv8Mn"
    },
    {
      "cell_type": "markdown",
      "id": "32e6be31-61d4-4d70-b97c-021869ac8e4c",
      "metadata": {
        "id": "32e6be31-61d4-4d70-b97c-021869ac8e4c"
      },
      "source": [
        "## **2. Elbow Plot and Cluster Plot Separate**\n",
        "\n",
        "#### Purpose:\n",
        "- Provides a visual understanding of the clusters formed by K-means.\n",
        "- Verifies the clustering results and checks for overlapping clusters or outliers.\n",
        "\n",
        "#### Steps for Cluster Plot:\n",
        "1. Fit the K-means model using the optimal `K`.\n",
        "2. Assign cluster labels to each data point.\n",
        "3. Create a scatter plot with points colored according to their cluster labels.\n",
        "4. Analyze the grouping and separation of clusters."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample Code:"
      ],
      "metadata": {
        "id": "zOVdtGdazOVV"
      },
      "id": "zOVdtGdazOVV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c430d5d-a474-48b0-80c2-863b43424c35",
      "metadata": {
        "id": "3c430d5d-a474-48b0-80c2-863b43424c35"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import minmax_scale\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Read the dataset\n",
        "dataset = pd.read_csv(\"studentclusters.csv\")\n",
        "X = dataset.copy()\n",
        "\n",
        "# Normalize the data for MinMax normalization\n",
        "X_scaled = minmax_scale(X)\n",
        "\n",
        "# Get the number of samples in the dataset\n",
        "n_samples = X_scaled.shape[0]\n",
        "\n",
        "# Elbow method to determine optimum clusters\n",
        "inertia_values = []  # To store inertia values\n",
        "inertia_change = []  # To track percentage change in inertia values\n",
        "\n",
        "# The maximum number of clusters should be at most the number of samples\n",
        "max_clusters = min(50, n_samples)\n",
        "\n",
        "# Try different numbers of clusters (from 2 to max_clusters)\n",
        "for i in range(2, max_clusters + 1):\n",
        "    kmeans = KMeans(n_clusters=i, random_state=42)  # Set random_state for reproducibility\n",
        "    kmeans.fit(X_scaled)\n",
        "    inertia_values.append(kmeans.inertia_)\n",
        "\n",
        "    # Calculate the percentage change in inertia compared to the previous inertia value\n",
        "    if i > 2:\n",
        "        prev_inertia = inertia_values[-2]\n",
        "        current_inertia = inertia_values[-1]\n",
        "\n",
        "        # Avoid division by zero by checking if the previous inertia is non-zero\n",
        "        if prev_inertia != 0:\n",
        "            change = (current_inertia - prev_inertia) / prev_inertia * 100\n",
        "            inertia_change.append(change)\n",
        "\n",
        "# Plotting the Elbow Curve\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)  # First plot (Elbow method)\n",
        "plt.plot(range(2, max_clusters + 1), inertia_values, marker='o')\n",
        "plt.title('Elbow Method for Optimal K')\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('Inertia (Sum of Squared Distances)')\n",
        "plt.grid(True)\n",
        "\n",
        "# Check for inertia change and automatically set optimal clusters if change is < 5% for 3 consecutive trials\n",
        "optimal_k = None\n",
        "for i in range(3, len(inertia_change)):\n",
        "    if all(abs(change) < 5 for change in inertia_change[i-3:i]):\n",
        "        optimal_k = i + 3  # We add 3 because the range starts from 2\n",
        "        break\n",
        "\n",
        "# If optimal_k was not set, take the last valid k\n",
        "if not optimal_k:\n",
        "    optimal_k = max_clusters\n",
        "\n",
        "# Fit the final KMeans model with the optimal_k\n",
        "kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
        "kmeans.fit(X_scaled)\n",
        "\n",
        "# Plot the clusters\n",
        "plt.subplot(1, 2, 2)  # Second plot (Cluster visualization)\n",
        "plt.scatter(X_scaled[:, 0], X_scaled[:, 1], c=kmeans.labels_, cmap='viridis')\n",
        "plt.title(f'Clusters for K={optimal_k}')\n",
        "plt.xlabel('Marks')\n",
        "plt.ylabel('Study Hours')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Output the optimal number of clusters determined\n",
        "print(f\"Optimal number of clusters: {optimal_k}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What Does the Code Achieve?\n",
        "\n",
        "### 1. Loads and Prepares the Data\n",
        "- The dataset is loaded using `pandas`, and a copy is made to ensure the original data remains intact.\n",
        "- The features in the dataset are normalized using Min-Max scaling to ensure fair contribution of all attributes during clustering.\n",
        "\n",
        "**Purpose**: Prepare the dataset for the K-means clustering algorithm by standardizing the feature scales.\n",
        "\n",
        "\n",
        "\n",
        "### 2. Determines the Optimal Number of Clusters\n",
        "- The Elbow Method is used to calculate **inertia values** for a range of clusters (`K` values).\n",
        "- **Inertia** is the sum of squared distances from data points to their nearest cluster center. Lower inertia values indicate tighter clusters.\n",
        "\n",
        "**Purpose**: Identify the optimal number of clusters by finding the \"elbow point\" where the rate of decrease in inertia slows significantly.\n",
        "\n",
        "\n",
        "\n",
        "### 3. Automates the Detection of Optimal Clusters\n",
        "- The percentage change in inertia values is calculated for successive cluster numbers (`K` values).\n",
        "- A heuristic checks if the inertia change stabilizes below a threshold (e.g., 5%) for three consecutive values of `K`. If this condition is met, the corresponding `K` is selected as the optimal number of clusters.\n",
        "\n",
        "**Purpose**: Automate the process of finding the optimal number of clusters, eliminating the need for manual interpretation of the Elbow Curve.\n",
        "\n",
        "\n",
        "\n",
        "### 4. Applies K-Means Clustering\n",
        "- The K-means algorithm is applied to the dataset using the optimal number of clusters (`K`).\n",
        "- Each data point is assigned to a cluster based on its proximity to the cluster centroids.\n",
        "\n",
        "**Purpose**: Partition the data into meaningful clusters based on the similarity of data points.\n",
        "\n",
        "\n",
        "\n",
        "### 5. Visualizes the Results\n",
        "- **Elbow Plot**: A line plot of inertia values against the number of clusters (`K`), helping visualize how inertia decreases as the number of clusters increases.\n",
        "- **Cluster Plot**: A scatter plot where each data point is colored according to its cluster assignment, visually demonstrating the grouping of data points.\n",
        "\n",
        "**Purpose**: Provide visual insights into the clustering process:\n",
        "  - The Elbow Plot helps identify the optimal `K`.\n",
        "  - The Cluster Plot shows the final cluster assignments.\n",
        "\n",
        "\n",
        "\n",
        "### 6. Outputs the Optimal Number of Clusters\n",
        "- Prints the optimal number of clusters determined by the Elbow Method and heuristic.\n",
        "\n",
        "**Purpose**: Inform the user about the ideal number of clusters for the dataset.\n"
      ],
      "metadata": {
        "id": "E2X8K3szxtXK"
      },
      "id": "E2X8K3szxtXK"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}